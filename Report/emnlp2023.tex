% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{hyperref}

% Remove the "review" option to generate the final version.
\usepackage{EMNLP2023}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}


% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Kaggle NLP competition report}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{Etienne Andrier \And Aymeric Conti \And Hadrien Crassous \AND Pierre Jourdin \And Maxime Vanderbeken}

\begin{document}
\maketitle
\begin{abstract}
We started by analyzing the data, then we have implemented some basic models to take advantage of the different caracters of each alphabet. We then explored the deep learning models mostly by fine-tuning relevant models. Finally, we analyzed the results.
\end{abstract}

\section{Introduction}

The objective of this work is to classify text based on their language. We were given 38 854 training data labeled with 389 different languages. And we had to classify the 190 551 unlabeled data.
\\
\\
The metric we used is accuracy : the proportion of correctly predicted samples. It is between 0 and 1, a random model has an accuracy of 1/389 $\approx$ \textbf{0.0026}.

\section{Solution}

\subsection{Analysis of the data}
First, we look at numerical information :
\begin{itemize}[noitemsep, topsep=0pt]
    \item 38 854 training data
    \item 389 unique languages (or labels)
    \item 6462 unique characters
\end{itemize}
We had to remove 100 lines of train because labels were NaN.
\\\\
We also want to look at how balanced the dataset is : \autoref{fig:data} shows that most languages have exactly 100 samples in the train set. The languages which have low samples (like 1) are technically an issue, but there is few of them so we consider the dataset balanced enough.
\\\\
We split the dataset in train (90\%) and validation (10\%) sets in order to esstimate the accuracy of our model.

\begin{figure}[h]
    \centering
    \includegraphics[width=\columnwidth]{images/data.png}  % Ensure it fits within the column
    \caption{The dataset is balanced enough}
    \label{fig:data}
\end{figure}

\subsection{Simple models}
Our first idea was that the difference of alphabets used across languages should allow us to make a first prediction.
\\
\\
The model used (StatModel) infer as follows :
given a text, the prediction is randomly sampled among the languages that have been seen with all the characters of the text in the train set.
\\\\
This model has a test accuracy of \textbf{0.27}
\\\\
We also did a similar model (StatModelOnlyIf1Language) : if there is exactly 1 language that matches all of the characters in the input text, we predict it, else we dont predict at all. This has an accuracy of 0.16 because most samples are unpredicted, but on the predicted instances we reach an accuracy of 0.91

\subsection{Deep models}
We then decided to fine-tune existing deep models, as training from scratch is only feasible with computational power and massive amount of data which we do not have.
\\
We chose to finetune \textbf{xlm-roberta-large} (2019) from Facebook. It has 561M parameters and is under MIT license. We chose it because :
\begin{itemize}[noitemsep, topsep=0pt]
    \item It is made to be finetuned
    \item it is popular on HuggingFace (https://huggingface.co/FacebookAI/xlm-roberta-large)
\end{itemize}

We got an accuracy of \textbf{0.89}

\section{Results and Analysis}


\bibliography{anthology,custom}
\bibliographystyle{acl_natbib}


\end{document}
